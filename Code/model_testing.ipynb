{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from vacances_scolaires_france import SchoolHolidayDates\n",
    "from jours_feries_france import JoursFeries\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"/Users/solalzana/Desktop/X/Python for Data Science/Final Project/bike_counters/data/train.parquet\")\n",
    "df_test_kaggle = pd.read_parquet(\"/Users/solalzana/Desktop/X/Python for Data Science/Final Project/bike_counters/data/final_test.parquet\")\n",
    "df_ext = pd.read_csv(\"/Users/solalzana/Desktop/X/Python for Data Science/Final Project/bike_counters/data/external_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned = prepare_data(df_train, df_ext)\n",
    "df_test_kaggle_cleaned = prepare_data(df_test_kaggle, df_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train = df_train_cleaned.drop(columns=[\"log_bike_count\", \"bike_count\", \"date\"])\n",
    "y_train = df_train_cleaned['log_bike_count']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "X_test_kaggle = df_test_kaggle # when testing on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If testing on kaggle then use provided test dataset instead of splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different models to be tested here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'random_forest': RandomForestRegressor(\n",
    "    #     n_estimators=100,\n",
    "    #     random_state=42\n",
    "    # ),\n",
    "    'xgboost': xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        enable_categorical=True  # Add this if you have categorical features\n",
    "    ),\n",
    "    'ridge': Ridge(\n",
    "        random_state=42\n",
    "    ),\n",
    "    'catboost': CatBoostRegressor(\n",
    "        iterations=100,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    pipeline, rmse = train_and_evaluate_model(X_train, X_test, y_train, y_test, model)\n",
    "    results[name] = {\n",
    "        'pipeline': pipeline,\n",
    "        'rmse': rmse\n",
    "    }\n",
    "    print(f\"{name} RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = min(results.items(), key=lambda x: x[1]['rmse'])\n",
    "print(f\"\\nBest model: {best_model[0]} with RMSE: {best_model[1]['rmse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline\n",
    "# import xgboost as xgb\n",
    "\n",
    "# fit_encoder(X_train)\n",
    "# # X_train = encoder(X_train)\n",
    "# # X_test = encoder(X_test)\n",
    "\n",
    "# model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "# trained_model = train_model(X_train, y_train, model)\n",
    "\n",
    "# test_model_kaggle(trained_model, X_test, \"xgb\") # results is a df storing y_pred(s)\n",
    "# # check submission folder now\n",
    "# # X_test.drop(columns=['date'], inplace=True)\n",
    "# # evaluate_model(trained_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "# model = CatBoostRegressor()\n",
    "# pipeline_cb = build_pipeline(X_train, y_train, model)\n",
    "# trained_model_cb = train_model(pipeline_cb, model, X_train, y_train)\n",
    "\n",
    "# # test_model_kaggle(pipeline_cb, X_test, \"cb\") # results is a df storing y_pred(s)\n",
    "# # # check submission folder now\n",
    "# test_model_kaggle(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lightgbm\n",
    "# !pip install lightgbm\n",
    "# from lightgbm import LGBMRegressor\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# model = lgb.LGBMRegressor()\n",
    "# pipeline_lgb = build_pipeline(X_train, y_train, model)\n",
    "# trained_model_lgb = train_model(pipeline_lgb, model, X_train, y_train)\n",
    "\n",
    "# test_model_kaggle(pipeline_lgb, X_test, \"lgb\") # results is a df storing y_pred(s)\n",
    "# # check submission folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# model = RandomForestRegressor(n_jobs=-1)\n",
    "# pipeline_cb = build_pipeline(X_train, y_train, model)\n",
    "# trained_model_cb = train_model(pipeline_cb, model, X_train, y_train)\n",
    "\n",
    "# test_model_kaggle(pipeline_xgb, X_test, \"rf\") # results is a df storing y_pred(s)\n",
    "# # check submission folder now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_best_model = tune_hyperparameters(best_model, X_train, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit predictions using the best model on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = best_model[1]['pipeline']\n",
    "submission, _ = test_model_kaggle(pipeline_best_model, X_test_kaggle, best_model[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
